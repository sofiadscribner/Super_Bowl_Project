{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia Table of Super Bowl 2024 Ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the html for the page and format it as text\n",
    "\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_Super_Bowl_commercials'\n",
    "r = requests.get(url)\n",
    "text = r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a beatiful soup object\n",
    "\n",
    "soup = BeautifulSoup(text)\n",
    "\n",
    "# find the heading for 2024\n",
    "\n",
    "heading = soup.find(\"h3\", {\"id\": \"2024_(LVIII)\"})\n",
    "\n",
    "# find the next table after that heading\n",
    "\n",
    "table_2024 = heading.find_next(\"table\", {\"class\": \"wikitable\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "current_product_type = None\n",
    "\n",
    "# loop through all rows in the table\n",
    "\n",
    "for row in table_2024.find_all(\"tr\"):\n",
    "    cells = row.find_all(\"td\")\n",
    "    \n",
    "    # skip the header row\n",
    "\n",
    "    if len(cells) == 0:\n",
    "        continue\n",
    "    \n",
    "    # if there's a product type in the first cell, update current_product_type\n",
    "\n",
    "    first_cell = row.find(\"td\")\n",
    "    if first_cell and first_cell.get(\"rowspan\"):\n",
    "        current_product_type = first_cell.text.strip()\n",
    "    \n",
    "    # if current_product_type is set, add it to the row only once\n",
    "\n",
    "    if current_product_type:\n",
    "\n",
    "        # check if the first cell already contains the current product type\n",
    "\n",
    "        if cells[0].text.strip() != current_product_type:\n",
    "            row_data = [current_product_type] + [cell.text.strip() for cell in cells]\n",
    "        else:\n",
    "            row_data = [cell.text.strip() for cell in cells]\n",
    "        \n",
    "        rows.append(row_data)\n",
    "    else:\n",
    "        # if there's no product type, just add the row as is\n",
    "        \n",
    "        row_data = [cell.text.strip() for cell in cells]\n",
    "        rows.append(row_data)\n",
    "\n",
    "def remove_citations(text):\n",
    "    return re.sub(r'\\[.*?\\]', '', text)\n",
    "\n",
    "for row in rows:\n",
    "    row[3] = remove_citations(row[3]) \n",
    "\n",
    "# manually fix rows that scraped incorrectly\n",
    "\n",
    "rows[8] = ['FIlm', 'Wicked', 'Trailer', 'Trailer']\n",
    "rows[22] = ['Retail', 'Bass Pro Shops', '\"Making Memories on the Water\"', 'Promotes Tracker fishing and pontoon boats.']\n",
    "rows[23] = ['Pharmaceutical', 'Pfizer', \"Here's to Science\", \"Various paintings, sculptures, and photographs of members of the science community lip synch to Queen's Don't Stop Me Now.\"]\n",
    "rows[24] = ['Restaurant', 'Popeyes', '\"Popeyes Finally Has Wings\"', 'Howie (played by Ken Jeong) was released from a fifty-year  cryosleep when a group scientists gave him a box of Popeyes wings while he discovers the future such as kick scooters, drones, etc.']\n",
    "rows[25] = ['Shoes', 'Skechers', '\"There\\'s No \\'T\\' in Skechers\"', 'Mr. T shows Tony Romo how he wears Skechers Slip-Ins where there\\'s no \"T\" in Skechers.']\n",
    "rows[62] = ['Political', 'American Values 2024', '\"American Values\"', 'In an advertisement for the Robert F. Kennedy Jr. 2024 presidential campaign, it reuses the advertisement of his uncle John F. Kennedyâ€™s presidential campaign, with images of Robert Jr. replacing images of John.']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract headers\n",
    "\n",
    "headers = [header.text.replace('[558]', '').strip() for header in table_2024.find_all(\"th\")]\n",
    "\n",
    "# create a DataFrame from the rows and headers\n",
    "\n",
    "df = pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "# looks perfect! save locally.\n",
    "\n",
    "# df.to_csv('wikipedia_ad_list.csv', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sofs_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
